---
title: 'Übung 06: Quanten Isingmodell'
author: "Tobias Blesgen und Leonardo Thome"
date: "21.07.2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes: 
 - \usepackage{amssymb}
 - \usepackage{amsmath}
 - \usepackage[ngerman]{babel}
 - \usepackage{physics}
 - \bibliographystyle{unsrtnat}
---

[//]: # Ausführbefehl im allgemeinen: ``render("ComputerPhysik06.Rmd")``

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Einführung

Das Isingmodell beschreibt die Gitterinteraktionen für Wellenausbreitungen. Um die Ausbreitung einer transversalen Welle auf einem eindimensionalen Gitter zu beobachten, schreiben wir den Hamilton-Operator der $N$ Gitterpunkte als:

\begin{equation}
  H = \sum^{N-2}_{i=0} \sigma_i^x \otimes \sigma^x_{i+1} + g \sum_{i=0}^{N-1} \sigma^z_i.
\end{equation}

Wir werden ihn, auf Zuständen basierend auf der Basis des Tensorprodukts aller Einspin-Zustände ($\ket{00..00}$ bis $\ket{11..11}$), anwenden, um ihn auf seine Grundzustandsenergie und -wellenfunktion, zu untersuchen. Das $g$ stellt hierbei die Kopplung an ein externes Feld.

Anschließend werden wir für $g=1$ den Phasenübergang für die Magnetisierung 

\begin{equation}
  M = \frac{1}{N} \bra{\psi} \sum_{i=0}^{N-1} \sigma_i^z \ket{\psi}
\end{equation}

betrachten.

# Implementation des numerischen Verfahrens

Der Hamiltonoperator in Matrixschreibweise wächst mit $2^{2N}$. Da wir bis zu $N=10$ Gitterpunkte betrachten wollen, würde eine Implementation in Form von Matrixmultiplikationen eine zeitlich sehr aufwendige Anwendung werden. Da die Matrix mit $((N-1)2^N)_{H_0} + (2^N)_{H_1}$ besetzten Elementen recht schwach besetzt ist, haben wir uns entschieden den Hamiltonoperator explizit als Funktion zu implementieren. So wird in einem \texttt{for}-Schleifen-System der Eingangsvektor $v$ in der Funktion \texttt{H}, mit dem zuvor für die Anzahl $N$ erzeugten \texttt{g_vektor}, zu $Hv$ überführt. 

## Eigenwerte und Eigenvektor

Um an den physikalisch interessanten Eigenvektor und den zugehörigen Eigenwert zu gelangen, haben wir versucht das Potenzverfahren zu implementieren. Dieses nimmt einen zufällig gewählten (normierten) Vektor und wendet ihn Auf den Operator an. Anschließend wird dieser Vektor normiert und das Verfahren beginnt von vorne. Der Vektor sollte nun mit hinreichend vielen Iterationen gegen der Vektor mit dem größten Eigenwert konvergieren. Sobald der Vektor sich nicht mehr deutlich ändert oder einer obere Schranke an Iterationen erreicht ist bricht das Verfahren ab und gibt den angenäherten Eigenvektor $\vec{e}$ aus. Den zugehörigen Eigenwert $\lambda$ erhalten wir aus der Operation $\vec{e} H \vec{e}$. Da dieses Verfahren nur den größten Eigenwert bestimmt muss anschließend die Operation um den Eigenwert $\lambda$ korregiert werden. Erneutes Anwenden des Verfahrens sollte den gesuchten niedrigsten Eigenwert ausgeben.

Leider konnten wir in unserem Verfahren, auch nach einem vollständigen Neuschreiben, nicht den Fehler ausfindig machen und sehen uns gezwungen, für die weitere Auswertung die \texttt{eigen} Funktion von r zu verwenden.

```{Rcpp}
#include<Rcpp.h>
#include<vector>
#include<algorithm>
#include<math.h>  
#include<iostream>
#include<random>
#include<stdio.h>
#include<stdlib.h>
#include<time.h>

using namespace Rcpp;
using namespace std;

// Berechnungsschritt des Skalierungsvektors: m = 0, pos = 0, dim(vektor) = n
void Hg_Rekursiv(const int n, int m, int l, int pos, std::vector<double>& vektor){
  vektor[pos] = (double)(n - l);
  for (int i = m; i < n; i++){
    Hg_Rekursiv(n, (i + 1), l+2 , pos + pow(2,i), vektor);
  }
}

// Skalierungsvektor (rechter H Term)
std::vector<double> g_Vektor(const int n){
  std::vector<double> vektor(pow(2,n));
  Hg_Rekursiv(n, 0, 0 , 0, vektor);
  return vektor;
}

// Normierungsbestimmung
double v_Norm(vector<double> const& u) {
    double sum = 0.;
    for (int i = 0; i < u.size(); ++i) {
        sum += u[i] * u[i];
    }
    return sqrt(sum);
}

// Zufälliger Startvektor
std::vector<double> random_V(const int l){
  std::vector<double> vektor(l);
  srand((time(NULL)));
  for (int i = 0; i < l; ++i) {
    vektor[i] = rand() % 100;
  }
  double norm = v_Norm(vektor);
  for (int i = 0; i < l; i++){
    vektor[i] /= norm;
  }
  
  return vektor;
}

// Anwendung von H
std::vector<double> H(std::vector<double> vektor, std::vector<double> gv, const double g, const int n){
  int size = pow(2,n);
  std::vector<double> neu(size);
  for (int i = 0; i < size; i++){
    neu[i] = gv[i]*g*vektor[i];
  }
  for (int i = 0; i < pow(2,n-2); i++){
    for (int j = 0; j < 4; j++){
      neu[i*4+j] += vektor[(i+1)*4-j-1];
    }
  }
  for (int i = 0; i < (n-2); i++){
    int mittel = pow(2,n-i-2);
    for (int grob = 0; grob < pow(2,i); grob++){
      for (int medium = 0; medium < 4; medium++){
        for (int j = 0; j < pow(2,n-i-2); j++){
          neu[(grob*4+medium)*mittel+j] += vektor[j+(4*(grob)+3-medium)*mittel];
        }
      }
    }
  }
  return neu;
}

// Hauptfunktion zur Eigenverktorbestimmung
//[[Rcpp::export]]
std::vector<double> eigene(const int n, const double g, const int max){
  const int l = pow(2,n);
  std::vector<double> vektor = random_V(l);
  std::vector<double> g_vektor = g_Vektor(n);
  double norm;
  
  for(int i=0; i<max; i++){
    vektor = H(vektor, g_vektor, g, n);
    norm = v_Norm(vektor);
    for (int j = 0; j < l; j++){
      vektor[j] /= norm;
    }
  }
  return vektor;
}

// Eigenwertbestimmung zum Eigenverktor
//[[Rcpp::export]]
double eigenwert(std::vector<double> eigenvektor, const double g, const int n){
  const int l = pow(2,n);
  std::vector<double> g_vektor = g_Vektor(n);
  std::vector<double> h_vektor = H(eigenvektor, g_vektor, g, n);
  double norm = v_Norm(eigenvektor);
  double sum = 0.;
  for(int j=0;j<l;j++){
      sum += eigenvektor[j]*h_vektor[j];
    }
  sum /= (norm*norm);
  return sum;
}  

// Matrixausgabe als Kontrolle 
//[[Rcpp::export]]
void matrixausgabe(const int n, const double g){
  int l = pow(2,n);
  std::vector<double> vektor(l);
  std::vector<double> g_vektor = g_Vektor(n);
  for (int i = 0; i<l; i++){
    for (int j = 0; j<l; j++){
      vektor[j] = 0;
    }
    vektor[i] = 1;
    vektor = H(vektor, g_vektor, g, n);
    for (int j = 0; j<l; j++){
      Rprintf("%d ", (int)(vektor[j]));
    }
    Rprintf("\n");
  }
  Rprintf("\n");
}

// Matrix weitergabe von H an R um dort weiter zu Rechnen
//[[Rcpp::export]]
std::vector<double> matrixH(const int n, const double g){
  int l = pow(2,n);
  std::vector<double> vektor(l);
  std::vector<double> Matrix(l*l);
  std::vector<double> g_vektor = g_Vektor(n);
  for (int i = 0; i<l; i++){
    for (int j = 0; j<l; j++){
      vektor[j] = 0;
    }
    vektor[i] = 1;
    vektor = H(vektor, g_vektor, g, n);
    for (int j = 0; j<l; j++){
      Matrix[l*i+j] = vektor[j];
    }
  }
  return Matrix;
}

// Matrix weitergabe von der Matrix für das Magneton an R
//[[Rcpp::export]]
std::vector<double> matrixM(const int n){
  int l = pow(2,n);
  std::vector<double> vektor(l);
  std::vector<double> Matrix(l*l);
  std::vector<double> g_neu_vektor = g_Vektor(n);
  
  for (int i = 0; i<l; i++){
    for (int j = 0; j<l; j++){
      Matrix[l*i+j] = 0;
      if(i == j){
        Matrix[l*i+j] = g_neu_vektor[i];
      }
    }
  }
  return Matrix;
}


// Anwendung von vom Shift um den Eigenwert aus der Matrix zu entfernen
std::vector<double> h_shift(std::vector<double> vektor, const double g, const int n, std::vector<double> eigenvektor){
  std::vector<double> g_vektor = g_Vektor(n);
  std::vector<double> h_vektor = H(vektor, g_vektor, g, n);
  const int l = pow(2,n);
  std::vector<double> neu(l);
  const double eigenw = eigenwert(eigenvektor, g, n);
  for (int i = 0; i < l; i++){
    neu[i] = h_vektor[i];
    for (int j = 0; j < l; j++){
      neu[i] -= (eigenw*eigenvektor[i]*eigenvektor[j]); 
    }
  }
  return neu;
}

// Eigenverktor der geshifteten Matrix, zum nächst größeren Eigenwert.
// Ist jedoch abhänig vom Starvektor und erzeugt beim auswerten Teils einen 
// größeren Eigenwert (falsch).
//[[Rcpp::export]]
std::vector<double> eigene_shift(const int n, const double g, const int max){
  // bestimmung des größten eigenwert-vektors
  std::vector<double> grosser_vektor = eigene(n, g, max);
  // bestimmung des kleinstenm eigenwert-vektors
  const int l = pow(2,n);
  std::vector<double> vektor = random_V(l);
  std::vector<double> g_vektor = g_Vektor(n);
  double norm;
  for(int i=0; i<max; i++){
    vektor = h_shift(vektor, g, n, grosser_vektor);
    norm = v_Norm(vektor);
    for (int j = 0; j < l; j++){
      vektor[j] /= norm;
    }
  }
  return vektor;
}

```

# Eigenwerte und Auswertung



```{r, echo=FALSE, fig.cap="\\label{fig:test} Test Verlauf", fig.width=7,fig.height=4}
#Nach Methode in C++ 

ca = 2:10
a = 2:10
d = 1:10

# g gegen N für g = 0 und N = 2,4,6,8,10 (?)
for (element in ca){
  b = eigene(element, 0, 1001)
  a[element-1] = eigenwert(b, 0,  element)
}
plot((2:10),a,"l")

# nur für g bis  g = 2 
for (color in d){
  for (element in ca){
    b = eigene(element, color/5, 1000)
    k = eigenwert(b, color/5,element)
    a[element-1] = k
  }
  lines((2:10),a,"l", col=rainbow(10)[color])
}

```
## Kopplungsabhängiges Verhalten

Wir wollen uns das Verhalten der Grundzustandsenergie (dem Eigenwert von $H$) für verschiedene $g$ ansehen. Hierzu tragen wir in Abb. \ref{fig:abb1} den Betrag der berechneten Grundzustandsenergien gegen die Kopplung $g$ auf.

```{r, echo=FALSE, fig.cap="\\label{fig:abb1} Eigenwertverhalten für g-Kopplungen"}
#Eigenwerte mit r für Energie g Kopplung

#Eigeaben von N und g (Speicherverktor a)
n <- c(2,4,6,8,10)
g <- seq(0,2, length.out= 10)
a <- rep(0,length(g))

#Erzeugen leeren Plot
plot(0,0,ylim =c(0,-20),xlim = c(0,2),"n")

# Für N´s wird die Abhänigkeit von g zu E bestimmt.
for (N in n){
  i = 1
  for (G in g){
    #Eigenwert zur Matrix
    ew <- eigen(matrix(matrixH(N,G), nrow = 2^N, ncol = 2^N))
    #Speichern kleisten Eigenwert
    a[i] = min(unlist(ew[1]))
    i = i+1
  }
  #Plot von g gegenüber den betimmten Eigenwerten (festes N)
  lines(g,a,"l", col=rainbow(length(g))[N])
}
```
Man kann ein klar divergierendes Verhalten der Grundzustandsenergien für größere Kopplungen erkennen. So starten die Grundzustands energie für verschiedene Gitterpunktmengen $N$ in gleichmäßigen Abständen und steigen betraglich für größere Kopplungen an. Über den gesammten Verlauf gilt für jedes $g_0$, dass bei $g=g_0$ die Energien einheitliche Abstände zu einander einhalten, wobei diese Abstände jedoch ebenfalls anwachsen.

Der Trend zu betraglich größeren Energien kann im physikalischen Sinne damit gedeutet werden, dass die Gitterpunkte zunehmend stärker von dem externen Feld beeinflusst werden und schwingen. Somit steigt ihre Energie betraglich monoton mit stärkeren Kopplungen an.

## Magnetisierungsverhalten

Wie in der Einleitung beschrieben, erwarten wir einen Phasenübergang in der Magnetisierung für $g=1$. Wie lassen uns daher für die verschiedenen Knotenmengen $N$ die Magnetisierung $M$ in Abb. \ref{fig:abb2} auftragen.

```{r, fig.cap="\\label{fig:abb2} Phasenübergang der Magnetisierung"}
#Eigenwerte mit r für Magnetisierung g Kopplung

#Eigeaben von N und g (Speicherverktor a)
n <- c(2,4,6,8,10)
g <- seq(0,2, length.out= 10)
a <- rep(0,length(g))

#Erzeugen leeren Plot
plot(0,0,ylim =c(0,1),xlim = c(0,2),"n")

# Für N´s wird die Abhänigkeit von g zu M bestimmt.
for (N in n){
  i = 1
  for (G in g){
    #Eigenwerte/verktoren zu H Matrix
    ew <- eigen(matrix(matrixH(N,G), nrow = 2^N, ncol = 2^N))
    #Eigenverktoren zum kleinsten Eigenwert.
    ev <- ew$vectors[,which.min(unlist(ew$values))]
    #Matrix Vektor Multiplikation ergibt nun die Magnetisierung.
    a[i] <- -1/N*(drop(t(ev) %*% (matrix(matrixM(N), nrow = 2^N, ncol = 2^N) %*% ev)))
    i = i+1
  }
  #Plot von g gegenüber der Magnetisierung (festes N)
  lines(g,a,"l", col=rainbow(length(g))[N])
}
```
Die Magnetisierungen aller aufgetragenen Gitterpunktmengen konvergieren von einer Magnetisierung von 0 gegen 1. Während für große $N$ die Kurve eine ehr S-förmige Sättigungskurve beschreibt, beginnt die Kurve für $N=2$ in einer Geraden deren Steigung monoton fällt, bis die gegen 1 konvergiert.

Wir können also gut sehen, dass für eine Kopplung von 1 eine Phasenübergang von keiner Magnetisierung zu einer vollständigen Magnetisierung zu beobachten ist.

# Fazit
Auch wenn unser Eigenwertsverfahren nicht funktioniert hat, konnten wir den Prozess nachvollziehen und berechnen. Das resultieren Ergebnis deckt sich mit unseren Erwartungen und der Phasenübergang konnte abgebildet werden.
